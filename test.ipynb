{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafabe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91cf0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e236c254",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\RagChatBot2\\venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'validate_default' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'validate_default' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "2025-10-10 12:34:06,035 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "# Load documents from the 'data' folder\n",
    "documents = SimpleDirectoryReader(input_dir='data').load_data()\n",
    "\n",
    "# Create an index\n",
    "index = VectorStoreIndex.from_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6564806d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\RagChatBot2\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 7/7 [00:00<00:00, 168.45it/s]\n",
      "Generating embeddings:   0%|          | 0/12 [00:00<?, ?it/s]2025-10-10 12:34:07,853 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 12/12 [00:01<00:00,  8.91it/s]\n"
     ]
    }
   ],
   "source": [
    "index=VectorStoreIndex.from_documents(documents,show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "379c925a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x21227aee710>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7595509",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "762eda0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 12:34:08,801 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 12:34:11,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "reponse=query_engine.query(\"What would be the data strategy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d54a6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data strategy involves building three data buckets for each profession: Domain knowledge (docs, templates, regulations), Interaction traces (conversations, transcripts, call notes), and Supervision & labeled datasets (intent, slot labels, ticket types, escalation flags). Tasks include crawling/purchasing domain corpora, defining annotation schema for labels, creating profession-specific instruction-tuning data, generating synthetic data, establishing privacy filters, and preparing datasets for pilot professions with validated pairs.\n"
     ]
    }
   ],
   "source": [
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c03879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 12:34:11,718 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 12:34:13,400 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "reponse=query_engine.query(\"user and personas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d3baad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business Owner (Client) and Platform Admin\n"
     ]
    }
   ],
   "source": [
    "print(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d05025e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 12:34:13,950 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 12:34:14,749 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: Business Owner (Client) and Platform Admin\n",
      "______________________________________________________________________\n",
      "Source Node 1/2\n",
      "Node ID: 3a3611b5-12bc-4478-b781-a560b1b99f22\n",
      "Similarity: 0.7661024446409759\n",
      "Text: 9) Safety & filter classifiers  Purpose: detect hallucinations,\n",
      "harmful/toxic content, PII leak, disallowed legal/medical advice.\n",
      "Implementation: ensembles of classifiers:  Toxicity model (Perspective\n",
      "API or in-house).  Hallucination detector (checking for unsupported\n",
      "facts by cross-checking retriever results).  Privacy filter (detect\n",
      "leakage o...\n",
      "______________________________________________________________________\n",
      "Source Node 2/2\n",
      "Node ID: df5b5786-0a49-47a5-b212-09883adbdb10\n",
      "Similarity: 0.7627976146254638\n",
      "Text: Functional Requirement Document (FRD)  Project Name: WhatsApp AI\n",
      "Agent SaaS Platform   Prepared For: Abhishek Srivastava   Version: 1.0\n",
      "Date: 12 Sept 2025    1. Project Overview  The platform will provide\n",
      "WhatsApp-based AI agents for global SMBs, enabling them to automate\n",
      "lead conversion,  onboarding, and helpdesk with minimal setup.  Key\n",
      "goal...\n",
      "Business Owner (Client) and Platform Admin\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "response = query_engine.query(\"user and personas\")\n",
    "pprint_response(response,show_source=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77fe78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "retriever=VectorIndexRetriever(index=index, similarity_top_k=5, postprocessor=SimilarityPostprocessor(similarity_cutoff=0.7))\n",
    "query_engine = RetrieverQueryEngine(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e946ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 12:34:15,231 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2025-10-10 12:34:16,352 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Response: SaaS Backend (Server Side) includes services such as\n",
      "Authentication Service, Business Setup Service, Number Provisioning\n",
      "Service, Bot Engine, Lead Processor Service, Conversation Manager,\n",
      "Credit Management, Moderation Layer, and Billing Service.\n",
      "______________________________________________________________________\n",
      "Source Node 1/5\n",
      "Node ID: df5b5786-0a49-47a5-b212-09883adbdb10\n",
      "Similarity: 0.791239088226744\n",
      "Text: Functional Requirement Document (FRD)  Project Name: WhatsApp AI\n",
      "Agent SaaS Platform   Prepared For: Abhishek Srivastava   Version: 1.0\n",
      "Date: 12 Sept 2025    1. Project Overview  The platform will provide\n",
      "WhatsApp-based AI agents for global SMBs, enabling them to automate\n",
      "lead conversion,  onboarding, and helpdesk with minimal setup.  Key\n",
      "goal...\n",
      "______________________________________________________________________\n",
      "Source Node 2/5\n",
      "Node ID: b11e830b-2726-4fd2-b3c0-675d8f0f8ade\n",
      "Similarity: 0.7908003093016586\n",
      "Text: Functional Requirement Document (FRD)  Project Name: WhatsApp AI\n",
      "Agent SaaS Platform  Prepared For: Abhishek Srivastava  Version: 1.0\n",
      "Date: 12 Sept 2025    1. Project Overview  The platform will provide\n",
      "WhatsApp-based AI agents for global SMBs, enabling them to automate\n",
      "lead conversion, onboarding, and helpdesk with minimal setup.  Key\n",
      "goals:  ...\n",
      "______________________________________________________________________\n",
      "Source Node 3/5\n",
      "Node ID: e8e82c4d-2d80-479a-8420-82baf3b21aa9\n",
      "Similarity: 0.7852051823657717\n",
      "Text: 3.3 End Customer (Lead)  ● Receives WhatsApp messages.    ●\n",
      "Interacts with AI agent for sales, onboarding, support.      4. Key\n",
      "Features  4.1 Client Mobile App  ● Login & Signup: Email, OTP, Google\n",
      "sign-in.    ● Business Setup: Name, category, language.    ● WhatsApp\n",
      "Activation:    ○ Connect existing number.    ○ Get new number via BSP\n",
      "provision...\n",
      "______________________________________________________________________\n",
      "Source Node 4/5\n",
      "Node ID: ec7fd115-3ca7-4dd8-a1a9-9196809ae71a\n",
      "Similarity: 0.7829332597110024\n",
      "Text: ● Authentication Service (multi-tenant).    ● Business Setup\n",
      "Service (stores profile, category, language).    ● Number Provisioning\n",
      "Service:    ○ Integrate with WhatsApp BSPs (e.g., 360Dialog, Gupshup).\n",
      "● Bot Engine:    ○ Powered by LLM.    ○ Supports tone & language\n",
      "configuration.    ○ Uses RAG (Vector DB) for business-specific\n",
      "knowledge.   ...\n",
      "______________________________________________________________________\n",
      "Source Node 5/5\n",
      "Node ID: 667d9fe2-41a4-4dbe-96ea-133c37b73c4b\n",
      "Similarity: 0.7753632251513325\n",
      "Text: ● Tenant management.    ● Credit adjustments.    ● Abuse\n",
      "monitoring (logs of flagged content).    ● Usage reports.      5.\n",
      "Integrations  ● WhatsApp Cloud API / BSP (360Dialog, Gupshup, Twilio).\n",
      "● Vector DB (ChromaDB, Pinecone, or Weaviate) for RAG.    ● OCR\n",
      "Service (Google Vision, AWS Textract).    ● Speech-to-Text (Google\n",
      "Speech API, Whisper...\n",
      "SaaS Backend (Server Side) includes services such as Authentication Service, Business Setup Service, Number Provisioning Service, Bot Engine, Lead Processor Service, Conversation Manager, Credit Management, Moderation Layer, and Billing Service.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.response.pprint_utils import pprint_response\n",
    "response = query_engine.query(\"SaaS Backend(Server Side)\")\n",
    "pprint_response(response,show_source=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fc67baf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'VectorStoreIndex' from 'llama_index' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m urlparse\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      4\u001b[39m     VectorStoreIndex,\n\u001b[32m      5\u001b[39m     SimpleDirectoryReader,\n\u001b[32m      6\u001b[39m     StorageContext,\n\u001b[32m      7\u001b[39m     load_index_from_storage\n\u001b[32m      8\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvector_stores\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpostgres\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PGVectorStore\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# --- Parse DATABASE_URL ---\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'VectorStoreIndex' from 'llama_index' (unknown location)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from urllib.parse import urlparse\n",
    "from llama_index import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "# --- Parse DATABASE_URL ---\n",
    "DATABASE_URL = os.getenv(\n",
    "    \"DATABASE_URL\",\n",
    "    \"postgresql+psycopg2://postgres:dell@localhost:5432/postgres\"\n",
    ")\n",
    "\n",
    "parsed_url = urlparse(DATABASE_URL)\n",
    "DB_USER = parsed_url.username\n",
    "DB_PASS = parsed_url.password\n",
    "DB_HOST = parsed_url.hostname\n",
    "DB_PORT = parsed_url.port\n",
    "DB_NAME = parsed_url.path[1:]  # skip leading '/'\n",
    "\n",
    "# --- Configure PGVectorStore ---\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    host=DB_HOST,\n",
    "    port=DB_PORT,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASS,\n",
    "    database=DB_NAME,\n",
    "    table_name=\"document_vectors\"  # you can rename this\n",
    ")\n",
    "\n",
    "# --- Build storage context ---\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "# --- Check if DB table is empty or already has vectors ---\n",
    "if vector_store.is_empty():\n",
    "    print(\"No existing index found. Creating new one...\")\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "    print(\"✅ Index created and stored in PostgreSQL.\")\n",
    "else:\n",
    "    print(\"Loading existing index from PostgreSQL...\")\n",
    "    index = load_index_from_storage(storage_context)\n",
    "    print(\"✅ Index loaded successfully.\")\n",
    "\n",
    "# --- Query Engine ---\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What are transformers?\")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
